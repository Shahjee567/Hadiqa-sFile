# -*- coding: utf-8 -*-
"""TableextractionDIGITAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ifIz67_-2aNxecqzpDbkYlqWejS63N94

# Paddle OCR Init
"""

!pip install paddlepaddle-gpu
!pip install "paddleocr>=2.0.1"
!pip install protobuf==3.20.0
!git clone https://github.com/PaddlePaddle/PaddleOCR.git
!wget https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl
!pip install -U layoutparser-0.0.0-py3-none-any.whl
!wget http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.19_amd64.deb
!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2.19_amd64.deb
!pip install pdf2image
!pip install poppler-utils
!sudo apt-get update
!sudo apt-get install poppler-utils

import cv2
import layoutparser as lp



def readTable(path):
#image=cv2.imread('/content/pages/Page_Number 0.jpg')
  print(path)
  image=cv2.imread(path)
  image = image[..., ::-1]
  # load model
  model = lp.PaddleDetectionLayoutModel(config_path="lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config",
                                        threshold=0.7,
                                        label_map={0: "Text", 1: "Title", 2: "List", 3:"Table", 4:"Figure"},
                                        enforce_cpu=False,
                                        enable_mkldnn=True)#math kernel library
        # detect

  layout=model.detect(image)

  return layout

"""# Ocr Compatability Checks"""

!apt-get install tesseract-ocr
!pip install pytesseract
!pip install pytesseract

import cv2
import pytesseract

def check_image_for_ocr(image_path):
    # Load the image using OpenCV
    image = cv2.imread(image_path)

    # Check resolution
    height, width = image.shape[:2]
    dpi = max(width, height)
    if dpi < 300:
        print("Low resolution. Consider using higher resolution image.")

    # Convert image to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Check contrast
    mean_brightness = gray_image.mean()
    if mean_brightness < 100 or mean_brightness > 200:
        print("Contrast might be too low or high. Adjust image contrast.")

    # Perform OCR using Tesseract
    text = pytesseract.image_to_string(gray_image)

    # Print the extracted text
    print("Extracted Text:")
    print(text)

    # Check for handwritten text (this is a simple check and might not catch all handwritten text)
    if any(char.isalpha() and char.islower() for char in text):
        print("Handwritten text might be present. OCR might not be accurate.")

    # Check if text is too small
    text_regions = pytesseract.image_to_boxes(gray_image)
    for region in text_regions.splitlines():
        _, _, _, _, _, text = region.split(' ', 5)
        if len(text) <= 2:  # Adjust the threshold as needed
            print("Small text detected. Consider using a larger image or better quality.")

    # Add more checks as needed

    print("OCR suitability checks completed.")

"""# Text Extractor for Spacy Recognition"""

!pip install PyMuPDF

import fitz  # PyMuPDF

def extract_text_from_pdf(pdf_path):
    try:
        # Open the PDF file
        pdf_document = fitz.open(pdf_path)

        text = ""
        # Loop through each page in the PDF
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            text += page.get_text()

        return text
    except Exception as e:
        print("Error:", e)
        return None
    finally:
        pdf_document.close()

"""# Spacy Part"""

! pip install -U spacy -q

import spacy
from spacy.tokens import DocBin
from tqdm import tqdm
import json

def gettrainedJson(annotation_filepath):
  nlp = spacy.blank("en") # load a new spacy model
  #nlp=spacy.load("/content/model-best")
  db = DocBin()
  f = open(annotation_filepath)
  #f = open('/content/pvr_training_data.json')

  TRAIN_DATA = json.load(f)

  for text, annot in tqdm(TRAIN_DATA['annotations']):
      doc = nlp(text)
      ents = []
      for start, end, label in annot["entities"]:
          span = doc.char_span(start, end, label=label)
          if span is None:
              print("\n")
              print("Skipping entity")
              print("\n")
          else:
              print(start,end,label)
              ents.append(span)
      doc.ents = ents
      db.add(doc)

  db.to_disk("./training_data.spacy") # save the docbin object

def model_load(text):
  ! python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency
  ! python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy
  nlp_ner = spacy.load("/content/model-last")
  doc = nlp_ner(text)
  spacy.displacy.render(doc, style="ent", jupyter=True) # display in Jupyter
  return doc

def SpacyExecution(pdf_path,annotation_filepath):
  text_from_pdf=extract_text_from_pdf(pdf_path)
  gettrainedJson(annotation_filepath)
  doc=model_load(text_from_pdf)
  return doc

"""# For writing Spacy part to excel"""

def WriteSpacyOutput(docu):
  data = []
  # Iterate through the tokens in the Doc object and extract relevant information
  for ent in docu.ents:
      data.append({
          "Attribute":ent.label_,
          "Value":ent.text })

  # Convert the data list into a DataFrame
  df = pd.DataFrame(data)
  pd.DataFrame(df).to_csv("Check.csv", mode='a',index=False,header=False)

"""#Bank Recognizer"""

def RecognizeBank(output):
  for out in output[0]:
    out_text = out[1][0].replace(":", "").replace(" ", "")
    if(out_text[4:8]=='MEZN'):
      print("it's a Meezan Bank Statement")
      return "Meezan Bank"
    elif(out_text[4:8]=="SCBL"):
      print("it's a Standard Chartered Bank Statement ")
      return "SCBL Bank"

"""# Text Recognition

"""

from paddleocr import PaddleOCR,draw_ocr
import os
ocr=PaddleOCR(lang='en',use_gpu=True)

def textrec(path,layout,output,Bank,im):
  x1=-1
  x2=-1
  y1=-1
  y2=-1

  if Bank=="Meezan Bank":
    for out in output[0]:
      if(out[1][0]=='Transaction Date'):
        x1=int(out[0][0][0])
        y1=int(out[0][0][1])
    for l in layout:
      if l.type == 'Table':
          x2 = int(l.block.x_2)
          y2 = int(l.block.y_2)

    if y1 ==-1 or y2==-1 or x1==-1 or x2==-1:
      x1=0
      y1=0
      y2=im.shape[0]
      x2=im.shape[1]

  elif Bank=="SCBL Bank":
    for out in output[0]:
      if(out[1][0]=='Date'):
        x1=int(out[0][0][0])
        y1=int(out[0][0][1])
    for out in output[0]:
      if(out[1][0]=='This is an electronic statement'):
        x2=im.shape[1]
        y2=int(out[0][0][1])

    if y1 ==-1 or y2==-1 or x1==-1 or x2==-1:
      x1=0
      y1=0
      y2=im.shape[0]
      x2=im.shape[1]

  newpath="/content/page0crop.jpg"
  cv2.imwrite(newpath,im[y1:y2,x1:x2])
  im=cv2.imread(newpath)
  image_height=im.shape[0]
  image_width=im.shape[1]
  output=ocr.ocr(im)

  boxes=[line[0] for line in output[0]]
  texts=[line[1][0] for line in output[0]]
  probabilities=[line[1][1]for line in output[0]]

  image_boxes=im.copy()
  for box,text in zip(boxes,texts):
    cv2.rectangle(image_boxes,(int(box[0][0]),int(box[0][1])),(int(box[2][0]),int(box[2][1])),(0,0,255),1)
    cv2.putText(image_boxes,text,(int(box[0][0]),int(box[0][1])),cv2.FONT_HERSHEY_SIMPLEX,1,(222,0,0),1)

  cv2.imwrite('detections.jpg', image_boxes)

  img = im.copy()
  horiz_boxes = []
  vert_boxes = []

  # Drawing Horizontal and Vertical Boxes based on Coordinates
  for box in boxes:
    x_h, x_v = 0,int(box[0][0])
    y_h, y_v = int(box[0][1]),0
    width_h,width_v = image_width, int(box[2][0]-box[0][0])
    height_h,height_v = int(box[2][1]-box[0][1]),image_height

    horiz_boxes.append([x_h,y_h,x_h+width_h,y_h+height_h])
    vert_boxes.append([x_v,y_v,x_v+width_v,y_v+height_v])

    cv2.rectangle(im,(x_h,y_h), (x_h+width_h,y_h+height_h),(0,0,255),1)
    cv2.rectangle(im,(x_v,y_v), (x_v+width_v,y_v+height_v),(0,255,0),1)

  boxes

  cv2.imwrite('horiz_vert.jpg',im)

        ############## NO MAX SUPPRESSION ##############
        # NMS for Horizontal Boxes
  horiz_out = tf.image.non_max_suppression(
            horiz_boxes,
            probabilities,
            max_output_size = 1000,
            iou_threshold=0.05,
            score_threshold=float('-inf'),
            name=None
        )

  horiz_lines = np.sort(np.array(horiz_out))


  im_nms = img.copy()
  for val in horiz_lines:
    cv2.rectangle(im_nms, (int(horiz_boxes[val][0]),int(horiz_boxes[val][1])), (int(horiz_boxes[val][2]),int(horiz_boxes[val][3])),(0,0,255),1)

  cv2.imwrite('im_nms.jpg',im_nms)

  # NMS for Vertical Boxes
  vert_out = tf.image.non_max_suppression(
            vert_boxes,
            probabilities,
            max_output_size = 1000,
            iou_threshold=0.01,
            score_threshold=float('-inf'),
            name=None
        )


  vert_lines = np.sort(np.array(vert_out))


  for val in vert_lines:
    cv2.rectangle(im_nms, (int(vert_boxes[val][0]),int(vert_boxes[val][1])), (int(vert_boxes[val][2]),int(vert_boxes[val][3])),(255,0,0),1)

  cv2.imwrite('im_nms.jpg',im_nms)

  ############## CONVERT TO CSV ##############
  out_array = [["" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]



  unordered_boxes = []

  for i in vert_lines:
    print(vert_boxes[i])
    unordered_boxes.append(vert_boxes[i][0])

  ordered_boxes = np.argsort(unordered_boxes)


  def intersection(box_1, box_2):
    return [box_2[0], box_1[1],box_2[2], box_1[3]]

  def iou(box_1, box_2):
    x_1 = max(box_1[0], box_2[0])
    y_1 = max(box_1[1], box_2[1])
    x_2 = min(box_1[2], box_2[2])
    y_2 = min(box_1[3], box_2[3])

    inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))
    if inter == 0:
      return 0

    box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))
    box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))

    return inter / float(box_1_area + box_2_area - inter)

  for i in range(len(horiz_lines)):
    for j in range(len(vert_lines)):
      resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]] )
      for b in range(len(boxes)):
        the_box = [boxes[b][0][0],boxes[b][0][1],boxes[b][2][0],boxes[b][2][1]]
        if(iou(resultant,the_box)>0.1):
          out_array[i][j] = texts[b]

  out_array=np.array(out_array)
  # empt=[]
  # emptcount=0
  # for i in out_array[0]:
  #   if i=='':
  #     empt.append(emptcount)
  #   emptcount=emptcount+1

  # for row in out_array:
  #   for val in empt:
  #     row = np.delete(row, val)

  # for row in out_array:
  #   if row[0]=='':
  #     row[1]=''
  #     row[2]=''
  #     row[-3]=''
  #     row[-2]=''
  #     row[-1]=''

  #   if row[0]!='' and (row[6]=='' and row[7]==''):
  #     row[0]=''
  #     row[-1]=''
  #     row[1]=''
        #filename = os.path.basename("/content/drive/MyDrive/POC/Bank Statements"+files)
        #filename_without_ext = os.path.splitext(filename)[0]
  pd.DataFrame(out_array).to_csv("Check.csv", mode='a',index=False,header=False)

"""# Main"""

import os
from pdf2image import convert_from_path
import tensorflow as tf
import numpy as np
import pandas as pd

pdf_path="/content/FullStmt_1691423465826_3520270222483_AbdullahAsad050.pdf"
#pdf_path="/content/StandardCharteredStatement_unlocked.pdf"
annotation_filepath="/content/BankAccount.json"

images=convert_from_path(pdf_path)

!mkdir pages

for i in range(len(images)):
  images[i].save('pages/Page_Number '+str(i)+'.jpg')

directory_path = "/content/pages"

# Get a list of files in the directory
files = os.listdir(directory_path)

# Sort the files based on their last modification time (oldest to newest)
sorted_files = sorted(files, key=lambda x: os.path.getmtime(os.path.join(directory_path, x)))
jpg_files = [file_name for file_name in sorted_files if file_name.lower().endswith(".jpg")]

PageCounter=0

doc=SpacyExecution(pdf_path,annotation_filepath)

for ent in doc.ents:
    print(ent.text,ent.label_)

WriteSpacyOutput(doc)

for files in jpg_files:
  files="/content/pages/"+files
  im=cv2.imread(files)
  output=ocr.ocr(im)
  if PageCounter==0:
    Bank = RecognizeBank(output)
  PageCounter=PageCounter+1
  layout=readTable(files)
  textrec(files,layout,output,Bank,im)